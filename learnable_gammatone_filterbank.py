# -*- coding: utf-8 -*-
"""Learnable Gammatone Filterbank.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVrnN8yVNgnjnxTn0zLONBZtsZrdse3N
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x  # code works on lower version of tensorflow

import tensorflow as tf
tf.__version__

tf.config.experimental_run_functions_eagerly(True)
tf.compat.v1.enable_eager_execution()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/LGFB/lgtfb-en

!pip install ipdb

import os
import time
import tensorflow as tf
import numpy as np
from sys import argv
import ipdb
import matplotlib
#matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline  
import gc
import pickle
import random
from multiprocessing import Pool

import numpy as np
import pandas as pd
from keras import optimizers, losses, activations, models
from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler
from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \
    concatenate
from numpy import random
import librosa
import numpy as np
import glob
import os
import pandas as pd
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from random import shuffle
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import numpy as np
import os
from random import shuffle
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import random

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline  
import gc
import pickle
import random
from multiprocessing import Pool

import numpy as np
import pandas as pd
from keras import optimizers, losses, activations, models
from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler
from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \
    concatenate
from numpy import random
import librosa
import numpy as np
import glob
import os
import pandas as pd
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from random import shuffle
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import numpy as np
import os
from random import shuffle
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import random

"""Data resampling and storing signals in a way model accepts"""

# get all signals in a list
import os  
import librosa
import librosa.display
import pylab 
import pandas as pd
import numpy as np
import struct
from scipy.io import wavfile as wav
import matplotlib.pyplot as plt
import IPython.display as ipd                                                                                                          
dir =  "/content/drive/MyDrive/DATA" 
paths = []  
y = []                                                                                                           
for root, subdirectories, files in os.walk(dir):
    for subdirectory in subdirectories:
        f = os.path.join(root, subdirectory)
        x = []
        for filename in os.listdir(f):
          #print(filename)
          t,ex = os.path.splitext(filename)
          if ex == ".wav":
            x.append(os.path.join(f,filename))
            #c = os.path.dirname(paths[-1])
            #c = os.path.basename(c)
            #print(c)
            #y.append(labels.get(c))
          else:
            continue
        paths.append(x)
print(len(paths))

# to check the response of a single signal from each class, make a list of the inputs
single = [paths[0][190],paths[1][190],paths[2][190],paths[3][190],paths[4][190]]
single

"""splitting into subsets that contain equal and same distribution of classes. make it 2 subsets in case of train/validation splits"""

# function for renaming the signal from original dataset and storing in the respective subset
# renaming name in the subste num_class label_class name_id(random number to differentiate signals from class)
import shutil
src = "/content/drive/MyDrive/DATA"
dest = "/content/drive/MyDrive/LGFB/lgtfb-en/Data/valvular"
labels = {'MR_New':0,'MVP_New':1,'AS_New':2,'N_New':3,'MS_New':4} 
def save_fold(files,fold,y):
  #c = os.path.dirname(files[0])
  cnt = 1
  for file in files:
    print(file)
    c = os.path.dirname(file)
    c = os.path.basename(c)
    label = labels.get(c)
    y.append(c)
    dest_path = os.path.join(dest, str(fold+1) + str('-') + str(cnt) + str('-') + str(c) + str('-') + str(label) + '.wav')
    cnt = cnt+1
    shutil.copy(file, dest_path)

import shutil
import numpy as np
import random
files = paths
x_train = []
y_train = []
x_test = []
y_test = []
for fold in range(2):  # change range for 5 if you need more subsets, 2 is for train/test split
  print(fold)
  for i in range(len(files)):
    x = files[i]
    print(len(files[i]))
    if fold != 1:  # fold!=number of folds-1 ; last subset contains all the remaining signals
      random_files = random.sample(x, 120)  # number of signals from each class in a subset 
      save_fold(random_files,fold,y_train)
      x_train = x_train + random_files
    else:
      random_files = x
      save_fold(random_files,fold,y_test)
      x_test = x_test + random_files
    #print(random_files)
    C  = list(set(files[i]) - set(random_files)) + list(set(random_files) - set(files[i]))
    print(len(C))
    files[i] = C
    print(len(files[i]))
    print("")
    print("")

"""for single signal from each class"""

# for storing the single signals from each class in appropriate format
# function for renaming the signal from original dataset and storing in the respective subset
import shutil
src = "/content/drive/MyDrive/DATA"
dest = "/content/drive/MyDrive/LGFB/lgtfb-en/Data/valvular1"
labels = {'MR_New':0,'MVP_New':1,'AS_New':2,'N_New':3,'MS_New':4} 
def save_fold(files,fold,y):
  #c = os.path.dirname(files[0])
  cnt = 1
  for file in files:
    print(file)
    c = os.path.dirname(file)
    c = os.path.basename(c)
    label = labels.get(c)
    y.append(c)
    dest_path = os.path.join(dest, str(fold+1) + str('-') + str(cnt) + str('-') + str(c) + str('-') + str(label) + '.wav')
    cnt = cnt+1
    shutil.copy(file, dest_path)

save_fold(single,2,y_train)

"""Data preparation. stores input signals in tfr records so that they can processed any time even after session ends. This way the split remains same"""

# function to handle variable length signals that pads with silence for shorter durations
input_length = 8000  # number of input samples you are going to send to model

batch_size = 32

def audio_norm(data):

    max_data = np.max(data)
    min_data = np.min(data)
    data = (data-min_data)/(max_data-min_data+0.0001)
    return data-0.5


def load_audio_file(file_path, input_length=input_length):
    data = librosa.core.load(file_path, sr=2000)[0] #, sr=16000
    if len(data)>input_length:
        
        
        max_offset = len(data)-input_length
        
        offset = np.random.randint(max_offset)
        
        data = data[offset:(input_length+offset)]
        
        
    else:
        
        max_offset = input_length - len(data)
        print(max_offset)
        
        offset = np.random.randint(max_offset)
        
        
        data = np.pad(data, (offset, input_length - len(data) - offset), "constant")
        
        
    data = audio_norm(data)
    return data

# this function stores the subset split signals in tfr records
import os
import ipdb
from audioread import NoBackendError

import librosa
import numpy as np
import tensorflow as tf
import csv

def bytes_feature(value):
  '''
  Creates a TensorFlow Record Feature with value as a byte array.
  '''

  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def int64_feature(value):
  '''
  Creates a TensorFlow Record Feature with value as a 64 bit integer.
  '''

  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def prepare_tfrecord_raw(example_paths, destination_path):
  # Open a TFRecords file for writing.
  writer = tf.io.TFRecordWriter(destination_path)
  for idx in range(len(example_paths)):
    # Load an audio file for preprocessing.
    print('Extracting %s' % example_paths[idx])
    try:
      samples = load_audio_file(example_paths[idx],8000)  # input length
    except NoBackendError:
      print('Warning: Could not load {}.'.format(example_paths[idx]))
      continue

    # parsing filename
    wav_id   = os.path.split(example_paths[idx])[-1].split('-')[1]
    label    = int(os.path.split(example_paths[idx])[-1].split('.')[0].split('-')[-1].split('_')[0])

    wav_id = bytes(wav_id, 'utf-8')

    example = tf.train.Example(features=tf.train.Features(feature={
      'wavform': bytes_feature(samples.flatten().tostring()),
      'label': int64_feature(label),
      'wav_id': bytes_feature(wav_id)
    }))
    writer.write(example.SerializeToString())
  writer.close()


# original dataset
SOUND_FILE_DIR = 'Data/valvular'
for fold in range(2):   # no of subsets
  wav_paths = [os.path.join(SOUND_FILE_DIR, f) for f in os.listdir(SOUND_FILE_DIR) if f.endswith('.wav') and f.startswith(str(fold+1))]
  print(len(wav_paths))
  print(" ")
  dest_path = os.path.join('Data/raw_esc_' + str(fold+1) +'.tfrecords')
  prepare_tfrecord_raw(wav_paths, dest_path)

"""MODEL"""

os.environ["TF_CPP_MIN_LOG_LEVEL"]="2"
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
#tf.logging.set_verbosity(tf.logging.ERROR)


# hyper parameters 
BATCH_SIZE = 20
EPOCHS = 200 #375#350#400 #250 
LEARNING_RATE = 1e-2
LR_DECAY_BASE = 1.02
#LEARNING_RATE = 1e-4
#LR_DECAY_BASE = 1.00
weight_decay = 1e-3
ALPHA = 1.0		# mixup alpha
N_CLASSES = 5
DKP = 0.25		# keep prob for dropout
EMA_DECAY = 0.90

trial   = 0
CV_IDX  = 0 # [0,... 4]  it traverses the subsets

tbpath = '/content/drive/MyDrive/LGFB2/lgtfb-en/Tensorboard/lgtfb_' + str(CV_IDX) + '_' + str(trial)
mpath = '/content/drive/MyDrive/LGFB2/lgtfb-en/Model/lgtfb_' + str(CV_IDX) + '_' + str(trial)  # stores the best model

tf.io.gfile.makedirs(tbpath)
tf.io.gfile.makedirs(mpath)

def CNN_JS3(X, is_training=False):
  with tf.name_scope('CNN'):
    # 1st convolutional layer
    h_conv1 = tf.layers.conv2d(X, 32, [5, 5], [1, 1], 'same', use_bias=False)
    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 4, 2, 1], strides=[1, 4, 2, 1], padding='SAME') 
    h_bn1   = tf.layers.batch_normalization(h_pool1, training=is_training)
    h_1     = tf.nn.relu(h_bn1)
    # 2nd convolutional layer
    h_conv2 = tf.layers.conv2d(h_1, 64, [5, 5], [1, 1], 'same', use_bias=False)
    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 4, 2, 1], strides=[1, 4, 2, 1], padding='SAME')
    h_bn2   = tf.layers.batch_normalization(h_pool2, training=is_training)
    h_2     = tf.nn.relu(h_bn2)
    # 3nd convolutional layer
    h_conv3 = tf.layers.conv2d(h_2, 128, [5, 5], [1, 1], 'same', use_bias=False)
    h_pool3 = tf.nn.max_pool(h_conv3, ksize=[1, 4, 2, 1], strides=[1, 4, 2, 1], padding='SAME')
    h_bn3   = tf.layers.batch_normalization(h_pool3, training=is_training)
    h_3     = tf.nn.relu(h_bn3)
    return h_1, h_2, h_3

# temporal average pooling and flatteing 2
def TAP_FLAT(X, kp = 1.0, RC = 32, is_training=False):
  tsX   = tf.shape(X)                                                   # [B x T x F x C]
  slX   = X.get_shape().as_list()
  Xtap  = tf.reduce_mean(X, 1)                                          # [B x F x C]
  Xr    = tf.reshape(Xtap, [tsX[0], slX[2]*slX[3]])                     # [B x FC]
  Xrd   = tf.nn.dropout(Xr, keep_prob = kp)                             # [B x FC]
  M     = tf.layers.dense(Xrd, RC, use_bias=False)                      # [B x RC]
  M     = tf.layers.batch_normalization(M, training=is_training)
  M     = tf.nn.relu(M)                                                 # [B x RC]
  return M

def get_getter(ema):
  def ema_getter(getter, name, *args, **kwargs):
    var = getter(name, *args, **kwargs)
    ema_var = ema.average(var)
    return ema_var if ema_var else var
  return ema_getter

def _get_filter_norm(filt):
  return tf.sqrt(tf.reduce_sum(filt*filt,[0,1,2],keep_dims=True)+1e-4)

# initialize center frequencies by using mel-scale
def init_cent_freq(num_chan, max_f = 2000.0): #22050.0
  mel_f  = np.linspace(0, 1127*np.log(1+max_f/700), num_chan+1, True)   # num_chan+1 points from 0 to max_mel
  ori_f  = 700 * (np.exp(mel_f / 1127) - 1)
  print("ori_f",ori_f)
  print("max_f",max_f)
  return ori_f


def freq2tf(freq, nBins=128, level=7):
  freq   = freq / freq[-1]                         # in [0~1]
  centBin = int(nBins/2)
  tree_freq = freq[centBin:centBin+1]
  for lev in range(1,level):
    for n in range(2**lev):
      step = int(nBins / (2**lev))
      st   = step*n
      ed   = step*(n+1)
      cr = int((st+ed)/2)
      tree_freq = np.concatenate((tree_freq, [(freq[cr]-freq[st])/(freq[ed]-freq[st])]))
  return tree_freq

def tf2freq(tree_freq, level=7, LS=3):
  freq = tf.zeros(shape=[1],dtype=tf.float32)
  for lev in range(level):
    N = freq.get_shape().as_list()[0]
    st = 2**lev-1
    ed = st*2 + 1
    freq = tf.reshape(tf.stack([freq,freq],1),shape=[N*2])
    split = tf.reshape(tf.stack([tf.log(tree_freq[st:ed]+1e-8),tf.log(1-tree_freq[st:ed]+1e-8)],1),shape=[N*2])
    freq = freq + split
  N     = freq.get_shape().as_list()[0]
  freq  = tf.stack([freq]*LS,1)
  split = tf.log(tf.constant([[1.0/LS]*LS],dtype=tf.float32))
  freq  = tf.reshape(freq + split, shape=[N*LS])
  nFreqDiff = tf.exp(freq)
  print("nFreqDiff",nFreqDiff)
  freq = tf.cumsum(nFreqDiff)
  print("freq",freq)
  maxfreq = freq[-1]
  print("maxfreq",maxfreq)
  freq = freq / maxfreq
  nFreqDiff = nFreqDiff / maxfreq
  print("freq1",freq)
  return [freq, nFreqDiff]


def inverse_sigmoid(sig_out):
  return -np.log(1/sig_out -1 + 1e-8)

def LGTFB(X, kSize=2048, nBins=128, LS=3, nChan=3, is_training=False):
  # new
 with tf.name_scope('LGTFB'):
  init_freq      = init_cent_freq(nBins)  # initialize cfreq
  level          = np.log2(nBins).astype(int)  # conversion of cfreq
  tree_freq_init = freq2tf(init_freq, nBins, level) # conversion of cfreq
  print("tree_freq_init",tree_freq_init)
  tree_freq_init = inverse_sigmoid(tree_freq_init)  # conversion of cfreq
  print("tree_freq_init inerse",tree_freq_init)   # conversion of cfreq
  tree_freq      = tf.nn.sigmoid(tf.get_variable('freq', [nBins-1], initializer=tf.constant_initializer(tree_freq_init)))

  print("tree_freq",tree_freq)
  [freq,nFreqDiff]  = tf2freq(tree_freq, level, LS)                
  temp = tf.convert_to_tensor(init_freq, np.float32)
  freq           = tf.reshape(freq, [1,nBins*LS,1])   # central freq  
  print("cfreq",freq.shape)   
  nFreqDiff      = tf.reshape(nFreqDiff, [1,nBins*LS,1]) * 2  # band width
  print("bwidth",nFreqDiff.shape)
  # gamma parameter
  scale     = tf.nn.sigmoid(tf.get_variable('scale', [1,nBins*LS,nChan], initializer=tf.zeros_initializer() ))
  print("scale",scale.shape)
  shape     = tf.exp(tf.get_variable('shape', [1,nBins*LS,nChan], initializer=tf.zeros_initializer())) # order
  print("shape",shape.shape)
  # make filters
  n      = tf.cumsum(tf.ones(shape=[kSize,nBins*LS,1],dtype=tf.float32),0)	# [2048x128x1] 
  print("n",n.shape)
  gamma_1  = tf.pow(n/kSize,shape-1)
  print("gamma1",gamma_1.shape)
  gamma_2  = tf.exp(-np.pi*nFreqDiff*scale*n)
  print("gamma2",gamma_2.shape)
  gamma  = gamma_1 * gamma_2
  gamma  = gamma / tf.reduce_mean(gamma,0,keep_dims=True)
  print("gamma",gamma.shape)
  tone   = tf.cos(np.pi*(freq*n))			
  kernel = gamma * tone	
  print("kernel1",kernel.shape)			
  kernel = tf.reshape(kernel,[kSize,1,1,nBins*LS*nChan])
  print("kernel2",kernel.shape)
  kernel /= _get_filter_norm(kernel)
  # calc filter bank output
  fbank  = tf.nn.conv2d(X, kernel, [1,32,1,1], padding='VALID')
  print("fbank1",fbank.shape)
  fbank  = tf.log(tf.abs(fbank)+1)
  print("fbank2",fbank.shape)
  tsX    = tf.shape(fbank)
  print("tsX",tsX)
  fbank  = tf.reshape(fbank, [tsX[0],tsX[1],nBins*LS,nChan])
  print("fbank3",fbank.shape)
  fbank  = tf.nn.max_pool(fbank, ksize=[1, 4, LS, 1], strides=[1, 4, LS, 1], padding='VALID') 
  print("fbank4",fbank.shape)
  return fbank,shape,freq,nFreqDiff,kernel,temp

def Model(X, drop_kp=1.0, is_training=False, scope='Model', reuse=None, getter=None):
  with tf.variable_scope(scope, reuse=reuse, custom_getter=getter):
    GTFB,shape,freq,nFreqDiff,kernel,init_freq= LGTFB(X, kSize=256,nBins=32, LS=2, nChan=1, is_training=is_training)	
    #GTFB = EN(GTFB,9) 
    c1, c2, c3 = CNN_JS3(GTFB, is_training)
    h3 = TAP_FLAT(c3, drop_kp, 256, is_training)
    h3 = tf.nn.dropout(h3, keep_prob=drop_kp)
    logit = tf.layers.dense(h3, N_CLASSES)
  return logit,GTFB,shape,freq,nFreqDiff,kernel,c1,init_freq

train_set_raw = [[
    'Data/raw_esc_1.tfrecords'
]]
valid_set_raw = [['Data/raw_esc_2.tfrecords']]
test_set_raw = [['Data/raw_esc_2.tfrecords']]
test_sets = [['Data/raw_esc_2.tfrecords']]
single_set_raw = [['Data/raw_esc_3.tfrecords']]

#decodes tfr records and reshapes 1D signals to (no of samplesx1x1) so that CNN can process this
input_length = 8000

batch_size = 20
def _parse_function_train_raw(example_proto):
  # parsing
  features = {'wavform': tf.io.FixedLenFeature([], tf.string),
              'label': tf.io.FixedLenFeature([], tf.int64),
	      'wav_id': tf.io.FixedLenFeature([], tf.string)}
  parsed_features = tf.io.parse_single_example(example_proto, features)

  # decode waveform
  waveform = tf.io.decode_raw(parsed_features['wavform'], tf.float32)
  waveform = tf.reshape(waveform, [-1,1,1])		# 1D sequence with variable length

  # repeating
  waveform = tf.cond(tf.less(tf.shape(waveform)[0], 8000), 
                     lambda: tf.tile(waveform, [tf.math.floordiv(20000,tf.shape(waveform)[0])+1, 1, 1]),
                     lambda: waveform)

  # cropping bootstrapping
  #waveform = tf.image.random_crop(waveform, [6000,1,1]) 

  # label
  label    = tf.cast(parsed_features['label'], tf.int64)

  # waf_id
  wav_id = parsed_features['wav_id']

  return waveform, label, wav_id


def _parse_function_eval_raw(example_proto):
  # parsing
  features = {'wavform': tf.io.FixedLenFeature([], tf.string),
              'label': tf.io.FixedLenFeature([], tf.int64),
	      'wav_id': tf.io.FixedLenFeature([], tf.string)}
  parsed_features = tf.io.parse_single_example(example_proto, features)

  # decode waveform
  waveform = tf.io.decode_raw(parsed_features['wavform'], tf.float32)
  waveform = tf.reshape(waveform, [-1,1,1])		# 1D sequence with variable length

  # repeating
  waveform = tf.cond(tf.less(tf.shape(waveform)[0], 8000),
                     lambda: tf.tile(waveform, [tf.math.floordiv(20000,tf.shape(waveform)[0])+1, 1, 1]),
                     lambda: waveform)

  # label
  label    = tf.cast(parsed_features['label'], tf.int64)
  # waf_id
  wav_id = parsed_features['wav_id']

  return waveform, label, wav_id

def get_train_dataset_raw(file_paths, batch_size=20):
  dataset = tf.data.TFRecordDataset(file_paths)
  dataset = dataset.map(_parse_function_train_raw, num_parallel_calls=4)
  dataset = dataset.shuffle(buffer_size=10000)
  dataset = dataset.batch(batch_size)
  return dataset

def get_eval_dataset_raw(file_paths, batch_size=1):
  dataset = tf.data.TFRecordDataset(file_paths)
  dataset = dataset.map(_parse_function_eval_raw, num_parallel_calls=4)
  dataset = dataset.batch(batch_size)
  return dataset

# Build our dataflow graph.
GRAPH = tf.Graph()
with GRAPH.as_default():
  ## placeholders
  is_training = tf.compat.v1.placeholder(tf.bool)
  drop_kp = tf.compat.v1.placeholder(tf.float32, shape=())

  ## input processing
  # datasets
  dataset_train = get_train_dataset_raw(train_set_raw[CV_IDX], batch_size=BATCH_SIZE)
  dataset_valid = get_eval_dataset_raw(valid_set_raw[CV_IDX])
  dataset_test  = get_eval_dataset_raw(test_set_raw[CV_IDX])
  # reinitializable iterator to get waveforms
  iterator        = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(dataset_train), (tf.TensorShape([None,None,1,1]), tf.TensorShape([None]), tf.TensorShape([None])))
  iter_init_train = iterator.make_initializer(dataset_train)
  iter_init_valid = iterator.make_initializer(dataset_valid)
  iter_init_test  = iterator.make_initializer(dataset_test)
  next_element = iterator.get_next()
  WAVEFORMS  = next_element[0]
  LABELS     = next_element[1]
  WAV_ID     = next_element[2]
  # waveform normalization
  Xm, Xv = tf.nn.moments(WAVEFORMS, axes=[1], keepdims =True)
  IX = tf.compat.v1.div((WAVEFORMS-Xm),tf.sqrt(Xv+1e-8))
  # mix-up
  LABELS_mix = tf.one_hot(LABELS, N_CLASSES, dtype=tf.float32)	# [B x 10]
  #[IX, LABELS_mix] = tf.cond(is_training, lambda: mixup(IX, LABELS_mix), lambda: [IX, LABELS_mix])

  ## Model
  pred_Y,GTFB,shape,freq,nFreqDiff,kernel,c1,init_freq = Model(IX, drop_kp, is_training)
  ## EMA (exponential moving averaging)
  ema_dec   = tf.compat.v1.placeholder(tf.float32, shape=())
  ema       = tf.train.ExponentialMovingAverage(decay=ema_dec, zero_debias=True)
  var_model = tf.get_collection('trainable_variables', 'Model')
  EMA_OP    = ema.apply(var_model)
  ema_Y,GTFB,shap,fre,nFreqDif,ker,c,init_fre = Model(IX, drop_kp, is_training, reuse=True, getter=get_getter(ema))

  ## objective function
  # sound classification loss
  sc_loss = tf.reduce_mean(-1.0 * tf.reduce_sum(LABELS_mix*tf.log(tf.nn.softmax(pred_Y) + 1e-10),1) )	# for mixup
  tf.summary.scalar("sc_loss", sc_loss)
  # l2_loss
  tvars = tf.trainable_variables()
  l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tvars if 'dense' in v.name and 'kernel' in v.name])
  tf.summary.scalar("l2_loss", l2_loss)
  # final cost
  COST = sc_loss + weight_decay*l2_loss

  ## calc num of tvars 
  nvars = 0
  for var in tvars:
    sh = var.get_shape().as_list()
    print(var.name, sh)
    nvars += np.prod(sh)
  print(nvars, 'total variables')

  ## computing gradients and optimization
  lr = tf.compat.v1.placeholder(tf.float32, shape=())
# OPTIMIZER = tf.train.AdamOptimizer(LEARNING_RATE)	# default epsilon 1e-08
  OPTIMIZER = tf.train.AdamOptimizer(lr)	# default epsilon 1e-08
  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
  with tf.control_dependencies(update_ops):
    grads,_ = tf.clip_by_global_norm(tf.gradients(COST,tvars),1)	# compute gradients and do clipping
    APPLY_GRADIENT_OP = OPTIMIZER.apply_gradients(zip(grads, tvars))	# apply gradients

  # evaluation
  correct_pred = tf.equal(tf.argmax(pred_Y, 1), tf.argmax(LABELS_mix,1))	# for mixup accuracy
  ACCURACY = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))
  predicted = tf.argmax(pred_Y, 1)
  actual = tf.argmax(LABELS_mix,1)
  TP = tf.count_nonzero(predicted * actual)
  TN = tf.count_nonzero((predicted - 1) * (actual - 1))
  FP = tf.count_nonzero(predicted * (actual - 1))
  FN = tf.count_nonzero((predicted - 1) * actual)
  # confusion matrix
  CONF_MAT = tf.confusion_matrix(LABELS, tf.argmax(pred_Y, 1), num_classes=N_CLASSES)
  # ema evaluation for EMA
  ema_correct_pred = tf.equal(tf.argmax(ema_Y, 1), tf.argmax(LABELS_mix,1))	# for mixup accuracy
  EMA_ACCURACY = tf.reduce_mean(tf.cast(ema_correct_pred, dtype=tf.float32))
  # confusion matrix for EMA
  EMA_CONF_MAT = tf.confusion_matrix(LABELS, tf.argmax(ema_Y, 1), num_classes=N_CLASSES)
 
  SUMMARIES_OP = tf.summary.merge_all()


# Start training the model.
with tf.Session(graph=GRAPH) as SESSION:
  # initialize first
  SESSION.run(tf.global_variables_initializer())
  # Create a tensorflow summary writer.
  SUMMARY_WRITER = tf.summary.FileWriter(tbpath, graph=GRAPH)
  # Create a tensorflow graph writer.
  GRAPH_WRITER = tf.train.Saver(max_to_keep=1)

  steps = 0     # for tf.summary stepB
  best_cost = float('Inf')
  best_acc  = float(0)
  best_model = 0

  train_acc_hist  = []
  valid_acc_hist  = []
  test_acc_hist   = []
  ema_valid_acc_hist  = []
  ema_test_acc_hist   = []
  train_cost_hist = []
  test_cost_hist   = []
  ord_hist = []
  cfreq_hist = []
  bwidth_hist = []
  init_cfreq = []

  for EPOCH in range(EPOCHS):
    # initialize an iterator over the training dataset.
    SESSION.run(iter_init_train)
    iters = 0
    costs = 0.0
    accs  = 0.0

    lr_decay = LR_DECAY_BASE ** (EPOCH)
    lr_epoch = LEARNING_RATE / lr_decay
    print('Epoch %d, Leanring rate = %.7f' % (EPOCH, lr_epoch))

    start_time = time.time()
    while True:
      try:
        _, summaries, COST_VAL, ACC_VAL = SESSION.run([APPLY_GRADIENT_OP, SUMMARIES_OP, COST, ACCURACY],
                           feed_dict={drop_kp: DKP, is_training: True, lr: lr_epoch})
        costs += COST_VAL
        accs  += ACC_VAL
        iters += 1
        if iters % 20 == 0:
          end_time = time.time()
          DURATION = end_time - start_time
          start_time = end_time
          print('Epoch %d, Iters %d, cost = %.6f (%.3f sec)' % (EPOCH, iters, (costs/iters), DURATION))
          SUMMARY_WRITER.add_summary(summaries, steps)
          steps += 1
      except tf.errors.OutOfRangeError:
        break
    end_time = time.time()
    DURATION = end_time - start_time
    SUMMARY_WRITER.add_summary(summaries, steps)
    steps += 1
    print(iters)
    print('Epoch %d, Train cost = %.6f, acc = %.6f (%.3f sec)' % (EPOCH, (costs/iters), (accs/iters),DURATION))
    train_acc_hist.append(accs/iters)
    train_cost_hist.append(costs/iters)

    ### EMA ###
    if EPOCH == 0:
      ema_dec_tmp = 0
    else:
      ema_dec_tmp = EMA_DECAY
    _ = SESSION.run([EMA_OP], feed_dict={ema_dec: ema_dec_tmp})

    # Valid
    SESSION.run(iter_init_valid)
    iters = 0
    accs  = 0.0
    costs = 0.0
    
    while True:
      try:
        ACC_VAL, COST_VAL= SESSION.run([EMA_ACCURACY,COST], feed_dict={drop_kp: 1.0, is_training: False, lr: 0.0})
        costs = costs + COST_VAL
        accs  += ACC_VAL
        iters += 1
      except tf.errors.OutOfRangeError:
        break
    final_acc  = (accs/iters)
    print(iters)
    print('(EMA) Epoch %d, Valid acc = %.6f' % (EPOCH,  final_acc))

    ema_valid_acc_hist.append(final_acc)
    test_cost_hist.append(costs/iters)

    # update best model
    if EPOCH > 19:
      if final_acc > best_acc:
        print('Best epoch is changed from %d to %d, Acc %.4f to %.4f' % (best_model, EPOCH, best_acc, final_acc))
        best_acc = final_acc
        best_model = EPOCH
        GRAPH_WRITER.save(SESSION, mpath+'/model', global_step=EPOCH)   # save the best model

    # Test
    SESSION.run(iter_init_test)
    iters = 0
    accs  = 0.0
    ord = 0.0
    cfreq = 0.0
    bwidth = 0.0
    order = []
    cfreq = []
    bwidth = []
    while True:
      try:
        ACC_VAL, ok,ck,bk,infreq = SESSION.run([EMA_ACCURACY,shape,freq,nFreqDiff,init_freq], feed_dict={drop_kp: 1.0, is_training: False, lr: 0.0})
        accs  += ACC_VAL
        if iters == 0:
          order.append(ok)  # intermediate learnable parameter values over the training
          cfreq.append(ck)
          bwidth.append(bk)
          init_cfreq.append(infreq)
        iters += 1
      except tf.errors.OutOfRangeError:
        break
    final_acc  = (accs/iters)
    print('(EMA) Epoch %d, Test acc = %.6f' % (EPOCH,  final_acc))
    ema_test_acc_hist.append(final_acc)
    ord_hist.append(order[0][0][40][0])   # to store one of the filters parameter values 
    cfreq_hist.append(cfreq[0][0][40][0])
    bwidth_hist.append(bwidth[0][0][40][0])
  epochs = range(1, len(train_acc_hist)+1)

  plt.figure(figsize=(10,8))
  plt.plot(epochs, train_acc_hist, label='Training accuracy')
  plt.plot(epochs, ema_valid_acc_hist,label='Validation accuracy')
  #plt.plot(epochs, ema_test_acc_hist, label='Test accuracy')
  plt.title('accuracy plot')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.show()

  #cost plot
  plt.figure(figsize=(10,8))
  plt.plot(epochs, train_cost_hist, label='Training loss')
  plt.plot(epochs, test_cost_hist,label='Validation loss')
  #plt.plot(epochs, ema_test_acc_hist, label='Test accuracy')
  plt.title('loss plot')
  plt.xlabel('Epochs')
  plt.ylabel('loss')
  plt.legend()
  plt.show()
  #order plot
  plt.figure(figsize=(10,8))
  plt.plot(epochs, ord_hist, label='order history')
  plt.title('order hist')
  plt.xlabel('Epochs')
  plt.ylabel('order')
  plt.legend()
  plt.show()
  #cfreq plot
  plt.figure(figsize=(10,8))
  plt.plot(epochs, cfreq_hist, label='central freq history')
  plt.title('cfreq hist')
  plt.xlabel('Epochs')
  plt.ylabel('cfreq')
  plt.legend()
  plt.show()
  #bwidth plot
  plt.figure(figsize=(10,8))
  plt.plot(epochs, bwidth_hist, label='bandwidth history')
  plt.title('bwidth hist')
  plt.xlabel('Epochs')
  plt.ylabel('bandwidth')
  plt.legend()
  plt.show()


  # test with the best model
  GRAPH_WRITER.restore(SESSION, tf.train.latest_checkpoint(mpath))
  print('Test using the best model %d in %s' % (best_model, mpath))
  SESSION.run(iter_init_test)
  iters = 0
  accs = 0.0
  conf_mat = np.zeros((2,2)).astype(int)
  while True:
    try:
      [ACCS_VAL, CONF_MAT_VAL] = SESSION.run([EMA_ACCURACY, EMA_CONF_MAT], feed_dict={drop_kp: 1.0, is_training: False, lr: 0.0})
      accs += ACCS_VAL
      conf_mat = conf_mat + CONF_MAT_VAL
      iters += 1
    except tf.errors.OutOfRangeError:
      break
  print('Test Accuracy : %.4f' % (accs/iters))
  print(conf_mat)
  print(test_sets)
  dataset_test1  = get_eval_dataset_raw(test_sets)  # iterators for testing and single examples
  iter_init_test1  = iterator.make_initializer(dataset_test1)
  dataset_single  = get_eval_dataset_raw(single_set_raw)
  iter_init_single  = iterator.make_initializer(dataset_single)

coeff = []
order = []
cfreq = []
bwidth = []

# test with the best model
with tf.Session(graph=GRAPH) as SESSION:
  GRAPH_WRITER.restore(SESSION, tf.train.latest_checkpoint(mpath))
  print('Test using the best model %d in %s' % (best_model, mpath))
  SESSION.run(iter_init_test)
  iters = 0
  accs = 0.0
  conf_mat = np.zeros((5,5)).astype(int)
  mat = np.zeros((5,5)).astype(int)
  #pred = []
  #true = []
  Tp = 0.0
  Tn = 0.0
  Fp = 0.0
  Fn = 0.0
  layers = []   # to store the convolutional layer output just after LGTFB layer
  filter_out = [] # to store the LGTFB out put
  while True:
    try:
      #tf.argmax(pred_Y, 1), tf.argmax(LABELS_mix,1)
      [ACCS_VAL, CONF_MAT_VAL,layer,conf,t,p,ok,ck,bk,weight,conv] = SESSION.run([EMA_ACCURACY, EMA_CONF_MAT,GTFB,CONF_MAT,LABELS_mix,pred_Y,shape,freq,nFreqDiff,kernel,c1], feed_dict={drop_kp: 1.0, is_training: False, lr: 0.0})
      accs += ACCS_VAL
      conf_mat = conf_mat + CONF_MAT_VAL
      if iters == 0:
        coeff.append(weight)
        order.append(ok)
        cfreq.append(ck)
        bwidth.append(bk)
      layers.append(conv)
      filter_out.append(layer)
      iters += 1
      mat = mat + conf
      print(t)
      print(p)
     # new_result = tf.argmax(t, 1).eval(session=tf.compat.v1.Session())
      #print(new_result)
      #pred = pred + new_result
      #new_result = tf.argmax(p, 1).eval(session=tf.compat.v1.Session())
      #true = true + new_result
      #print(new_result)
      #break
      #pred.append(tf.argmax(p, 1).eval(session=tf.compat.v1.Session())[0])
      #true.append(tf.argmax(t, 1).eval(session=tf.compat.v1.Session())[0])
     # print(pred)
      #print(true)
      #break
      #Tp = Tp+tp
      #Tn = Tn + tn
      #Fp = Fp + fp
      #Fn = Fn + fn
      #if iters%20 == 0:
          #layers.append(layer)
      #print(layer)
      #output = layer
      #break
      #activations = np.array(activations).squeeze()
      #print(activations)
    except tf.errors.OutOfRangeError:
      break
  print('Test Accuracy : %.4f' % (accs/iters))
  print(conf_mat)
  #m = tf.confusion_matrix(true, pred, num_classes=N_CLASSES)
  #c = tf.compat.v1.metrics.recall(true,pred)
  #Truey = true.eval(session=tf.compat.v1.Session())
  #print(Truey)
  #Pred = pred.eval(session=tf.compat.v1.Session())
  #print(Pred)

# classification report
x = conf_mat
# Function for performance report.
def performance_report(arr):
    col = len(arr)
    print(col)
    # col=number of class
  
  
    cr = dict()
    support_sum = 0
      
    # macro avg of support is
    # sum of support only, not the mean.
    macro = [0]*3  
      
    # weighted avg of support is
    # sum of support only, not the mean.
    weighted = [0]*3
    for i in range(col):
        #vertical_sum = 0
        #for j in range(col): 
          #print("J")
          #print(i)
          #print(j)
          #print(arr[j][i])
          #vertical_sum= vertical_sum + arr[j][i] 
        vertical_sum= sum([arr[j][i] for j in range(col)])
        horizontal_sum= sum(arr[i])
        p = arr[i][i] / vertical_sum
        r = arr[i][i] / horizontal_sum
        f = (2 * p * r) / (p + r)
        s = horizontal_sum
        row=[p,r,f,s]
        support_sum+=s
        for j in range(3):
            macro[j]+=row[j]
            weighted[j]+=row[j]*s
        cr[i]=row
  
    # add Accuracy parameters.
    truepos=0
    total=0
    for i in range(col):
        truepos+=arr[i][i]
        total+=sum(arr[i])
  
    cr['Accuracy']=["", "", truepos/total, support_sum]
  
    # Add macro-weight and weighted_avg features.
    macro_avg=[Sum/col for Sum in macro]
    macro_avg.append(support_sum)
    cr['Macro_avg']=macro_avg
  
    weighted_avg=[Sum/support_sum for Sum in weighted]
    weighted_avg.append(support_sum)
    cr['Weighted_avg']=weighted_avg
  
    # print the classification_report
    print("Performance report of the model is :")
    space,p,r,f,s=" ","Precision","Recall","F1-Score","Support"
    print("%13s %9s %9s %9s %9s\n"%(space,p,r,f,s))
    stop=0
    for key,value in cr.items():
        if stop<col:
            stop+=1
            print("%13s %9.2f %9.2f %9.2f %9d"%(key,value[0],
                                                value[1],
                                                value[2],
                                                value[3]))
        elif stop==col:
            stop+=1
            print("\n%13s %9s %9s %9.2f %9d"%(key,value[0],
                                              value[1],
                                              value[2],
                                              value[3]))
        else:
            print("%13s %9.2f %9.2f %9.2f %9d"%(key,
                                                value[0],
                                                value[1],
                                                value[2],
                                                value[3]))
cr=performance_report(x)

# plot filter outputs
import matplotlib.pyplot as plt 
for i in range(len(filter_out)):
  temp = filter_out[i][0].transpose()
  print(temp[0].shape)
  print(len(temp[0]))
  fig = plt.figure(figsize=(20, 20))
  for j in range(len(temp[0])):
    plt.subplot(8, 4, j+1)    
    plt.plot(temp[0][j])
  fig.tight_layout(pad=3.0)
  plt.show()
  print(" ")
  print(" ")

# activation maps
def plot_feature_maps(feature_maps):
    height, width, depth = feature_maps.shape
    nb_plot = int(np.rint(np.sqrt(depth)))
    fig = plt.figure(figsize=(20, 20))
    for i in range(depth):
        #plt.subplot(8,4, i+1)
        plt.imshow(feature_maps[:,:,i], cmap='viridis')
        plt.title('feature map {}'.format(i+1))
        fig.savefig('/content/drive/MyDrive/feature_maps/MS/feature map {}'.format(i+1))
    fig.tight_layout(pad=3.0)
    plt.show()
for output in layers:
  first_layer_activation = output
  plot_feature_maps(first_layer_activation[0])
  print(" ")